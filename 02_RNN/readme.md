# Неделя 2: RNN и пайплайны

* Лекция: [слайды](https://github.com/ml-dafe/ml_mipt_dafe/blob/main/02_RNN/lec2.pdf), [запись]()
* Семинар: [содержание](https://github.com/ml-dafe/ml_mipt_dafe/blob/main/02_RNN/seminar/practice.ipynb), [запись]()

## Лекция

1. Последовательность данных
2. Устройство RNN, LSTM
3. Проблема затухания и взрыва градиентов моделей

## Семинар

1. Запуск RNN моделей
2. Построение кастомного Dataset
3. Цикл обучения


## Литература

Про RNN
- [Recurrent Neural Networks and Language Models](https://www.youtube.com/watch?v=TkFBozjO72Y)
- [Introduction to RNN and LSTM](https://www.theaidream.com/post/introduction-to-rnn-and-lstm)
- [A Beginner’s Guide on Recurrent Neural Networks with PyTorch](https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/)
- [Torch RNN. Docs](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)

Про Datasets и DataLoaders в torch
- [Datasets & DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)
- [A detailed example of how to generate your data in parallel with PyTorch](https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel)

Разное
- [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/)
- [Building Models with PyTorch](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html)
- [torchinfo](https://github.com/TylerYep/torchinfo)
- [Exploding and Vanishing Gradients](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L15%20Exploding%20and%20Vanishing%20Gradients.pdf)
